# QuestionSimilarity: Kaggle https://www.kaggle.com/c/quora-question-pairs


Problem Statement: Calculate probability of duplicity of question pairs given training data.


Proposed Solution:
I used word2vec model to generate vectors for each word of question pairs in a vector space. Each unique word gets unique vector. In word2vec model, word vectors capture the semantic and syntactic properties of the world based on the co-occurrence of the words in the corpus. Therefore, I thought to use these vectors as features for my model. I tried logistic regression and multi layer perceptron neural network with one hidden layer model to predict the similarity (probability) between question pairs. 


Implementation:

I followed following steps to predict question similarity (probability) for given question pairs (test data)-

Data Understanding and Preparation for Modeling:

In this phase, I tried to analyze data by looking at statistics, size, dimension, etc of datasets. 
I calculated distribution of labels (isduplicate) to validate if training data has unequal distribution of labels or not. It was   around (37\%-‘1’ and 63\%-‘0’) cases.

Then, I took word2vec pre-trained Google News corpus from link. Then I trained word2vec model using ‘gensim’ library using this        corpus.

Once I had a trained word2vec model, I created a dictionary ‘embedding array’ where I stored all unique words present in the train data and their corresponding vectors from word2vec model.

Later, I used this dictionary as look up while training to find out vectors for words.I divided the training data into train (90%) and dev (10%) data. Again this 10% data had distribution of classes (37\%-‘1’ and 63\%-‘0’). Therefore, for testing unbiased prediction from model, I made distribution of both classes (0 and 1) equal (50-50%) in dev data.

Training:

The feature vector for a sentence (question) was generated by taking the average of the word vectors corresponding to words in the sentence.

I trained a logistic regression model using TensorFlow with different parameters in the beginning. I got 68\% accuracy on dev data.

Then, I extended my model with a multilayer perceptron neural network with one hidden layer. I ran model for different parameters (learning rate, epochs, hidden layer nodes). I got best accuracy of 79\% on dev data with parameters (learning rate=0.01, epochs=10, hidden layer nodes=1000).


